{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook\n",
    "An obstacle for getting started with Neuroglancer is the data formats you can feed it are somewhat unfamiliar. For example, it does not accept TIFF format. It does this for a good reason though which is to be more efficient. One of the formats it accepts is called \"precomputed\" format, and that is the one we will use in this notebook. Fortunately there is a python pipeline for making precomputed data from TIFF files. \n",
    "\n",
    "Neuroglancer also is not set up to read CSV files. Instead, it uses the JSON file format, which essentially look like python dictionaries.\n",
    "\n",
    "This notebook covers how to convert a custom annotated atlas volume (of the same format as the 'WHS_SD_rat_atlas_v3_annotation.tif' file on bucket) to precomputed format so that you can load it in to Neuroglancer. It then covers how to make a 3d mesh from this volume so that the atlas can be viewed in the 3d viewer within Neuroglancer. It also covers how to convert a CSV file formatted like the 'labels_v3.csv' file on bucket containing the region name mapping for the Rat MRI atlas into JSON format so that Neuroglancer can read it and display the region names.\n",
    "\n",
    "In the following I use the original MRI atlas annotation volume and CSV file as an example. To use custom annotation volume and/or custom CSV file, replace the variables at the top of the notebook with your custom ones. The rest of the notebook should not (hopefully!) need to be changed before running.\n",
    "\n",
    "## A quick note about Neuroglancer\n",
    "Neuroglancer loads in datasets in \"layers\". A layer can be of type \"image\" (like what you would get as output from the light sheet microscope) or type \"segmentation\" (like an atlas annotation volume). The naming is a little confusing because both layer types refer to volumes (3-d objects). In this notebook, we are only concerned with a single layer: the annotation volume, which is a segmentation layer. If you were to make multiple annotation volumes (with different boundaries, etc.), each one of those would be a different layer. In Neuroglancer, you can overlay multiple layers or view them side-by-side. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "In order to run the code in this notebook, you will need a conda environment with python3 and containing some additional libraries. This environment \"ng_mriatlas\" can be set up in the following way:\n",
    "In terminal:\n",
    "- conda create -n ng_mriatlas python=3.7.4 -y\n",
    "- conda activate ng_mriatlas # (or source activate ng_mriatlas, depending on which version of conda you have)\n",
    "- pip install cloud-volume\n",
    "- pip install SimpleITK\n",
    "- **pip install neuroglancer==2.8** <br>\n",
    "\n",
    "\\# Optional: if you want 3d meshing following the next steps\n",
    "- git clone https://github.com/seung-lab/igneous.git igneous\n",
    "- cd igneous\n",
    "- pip install -r requirements.txt \n",
    "- python setup.py develop\n",
    "\n",
    "\\# To enable you to use jupyter notebooks to work with this environment as a kernel:\n",
    "- pip install --user ipykernel\n",
    "- python -m ipykernel install --user --name=ng_mriatlas\n",
    "\n",
    "Once this is all installed, make sure to select this conda environment as the kernel when running this notebook (you might have to restart the notebook server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,csv,json\n",
    "import numpy as np\n",
    "from cloudvolume import CloudVolume\n",
    "from cloudvolume.lib import mkdir, touch\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import neuroglancer\n",
    "from taskqueue import LocalTaskQueue\n",
    "import igneous.task_creation as tc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created /home/emilyjanedennis/Desktop/GitHub/ng/schwarz_in_MRIr\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Point to the custom annotation volume file that you have modified (in this example we point to the original one) \n",
    "custom_vol_path = '/home/emilyjanedennis/Desktop/for_registration_to_lightsheet/output_dirs/schwarz_atlas_toMRIr/result.tif'\n",
    "layer_dir = '/home/emilyjanedennis/Desktop/GitHub/ng/schwarz_in_MRIr'\n",
    "mkdir(layer_dir)\n",
    "print(f\"created {layer_dir}\")\n",
    "cpus_to_use = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Write the instructions (\"info\") file that will tell Neuroglancer about your volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_info_file(resolution_xyz,volume_size_xyz,layer_dir):\n",
    "    \"\"\" Make an JSON-formatted file called the \"info\" file\n",
    "    for use with the precomputed data format. \n",
    "    Precomputed is one of the formats that Neuroglancer can read in.  \n",
    "    --- parameters ---\n",
    "    resolution_xyz:      A tuple representing the size of the pixels (dx,dy,dz) \n",
    "                         in nanometers, e.g. (20000,20000,5000) for 20 micron x 20 micron x 5 micron\n",
    "    \n",
    "    volume_size_xyz:     A tuple representing the number of pixels in each dimension (Nx,Ny,Nz)\n",
    "    \n",
    "                         \n",
    "    layer_dir:           The directory where the precomputed data will be\n",
    "                         saved\n",
    "    \"\"\"\n",
    "    info = CloudVolume.create_new_info(\n",
    "        num_channels = 1,\n",
    "        layer_type = 'image', # 'image' or 'segmentation'\n",
    "        data_type = 'uint16', # 32 not necessary for atlases unless you have > 2^(32)-1 labels  \n",
    "        encoding = 'raw', # other options: 'jpeg', 'compressed_segmentation' (req. uint32 or uint64)\n",
    "        resolution = resolution_xyz, # X,Y,Z values in nanometers, 40 microns in each dim\n",
    "        voxel_offset = [ 0, 0, 0 ], # values X,Y,Z values in voxels\n",
    "        chunk_size = [ 1024, 1024, 1 ], # rechunk of image X,Y,Z in voxels.\n",
    "        volume_size = volume_size_xyz, # X,Y,Z size in voxels\n",
    "    )\n",
    "\n",
    "    vol = CloudVolume(f'file://{layer_dir}', info=info)\n",
    "    vol.provenance.description = \"A test info file\" # can change this if you want a description\n",
    "    vol.provenance.owners = [''] # list of contact email addresses\n",
    "    # Saves the info and provenance files for the first time\n",
    "    vol.commit_info() # generates info json file\n",
    "    vol.commit_provenance() # generates provenance json file\n",
    "    print(\"Created CloudVolume info file: \",vol.info_cloudpath)\n",
    "\n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created CloudVolume info file:  file:///home/emilyjanedennis/Desktop/GitHub/ng/schwarz_in_MRIr/info\n"
     ]
    }
   ],
   "source": [
    "## Make the info file\n",
    "\n",
    "#20 micron resolution in nm\n",
    "resolution_xyz = (39000,39000,39000)\n",
    "# Load the volume into memory and get its shape \n",
    "annotation_vol = np.array(sitk.GetArrayFromImage(\n",
    "    sitk.ReadImage(custom_vol_path)),dtype=np.uint16,order='F')\n",
    "z_dim,y_dim,x_dim = annotation_vol.shape\n",
    "volume_size_xyz = (x_dim,y_dim,z_dim)\n",
    "\n",
    "# Write the info file\n",
    "vol = make_info_file(\n",
    "    resolution_xyz=resolution_xyz,\n",
    "    volume_size_xyz=volume_size_xyz,\n",
    "    layer_dir=layer_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Convert annotation volume to precomputed data format\n",
    "First we create a directory (the \"progress_dir\") at the same folder level as the layer directory to keep track of the progress of the conversion. \n",
    "All the conversion does is copy the numpy array representing the 3d volume to a new object \"vol\". This is done one plane at a time (although it is parallelized). As each plane is converted, an empty file is created in the progress_dir with the name of the plane. By the end of the conversion, there should be as many files in this progress_dir as there are z planes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created directory: /home/emilyjanedennis/Desktop/GitHub/ng/progress_schwarz_in_MRIr\n"
     ]
    }
   ],
   "source": [
    "layer_name = layer_dir.split('/')[-1]\n",
    "parent_dir = '/'.join(layer_dir.split('/')[:-1])\n",
    "progress_dir = mkdir(parent_dir+ f'/progress_{layer_name}') # unlike os.mkdir doesn't crash on prexisting \n",
    "print(f\"created directory: {progress_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_slice(z):\n",
    "    \"\"\" This function copies a 2d image slice from the atlas volume\n",
    "    to the cloudvolume object, vol. We will run this in parallel over \n",
    "    all z planes\n",
    "    ---parameters---\n",
    "    z:    An integer representing the 0-indexed z plane to be converted\n",
    "    \"\"\"\n",
    "    if os.path.exists(os.path.join(progress_dir, str(z))):\n",
    "        print(f\"Slice {z} already processed, skipping \")\n",
    "        return\n",
    "    if z >= z_dim: # z is zero indexed and runs from 0-(z_dim-1)\n",
    "        print(\"Index {z} >= z_dim of volume, skipping\")\n",
    "        return\n",
    "    print('Processing slice z=',z)\n",
    "    array = annotation_vol[z].reshape((1,y_dim,x_dim)).T\n",
    "    vol[:,:, z] = array\n",
    "    touch(os.path.join(progress_dir, str(z)))\n",
    "    return \"success\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 455 planes to upload\n",
      "Processing slice z=Processing slice z=Processing slice z=Processing slice z=Processing slice z=Processing slice z=Processing slice z=Processing slice z=      0  7214\n",
      "36\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s]\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slice z="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing slice z="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slice z=  Processing slice z=910"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing slice z="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slice z="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slice z=12\n",
      " Processing slice z=\n",
      " 14\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slice z=Processing slice z= Processing slice z="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1718\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing slice z="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slice z="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s].55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Processing slice z="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21Processing slice z=Processing slice z= \n",
      " 2223\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s]\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slice z="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing slice z=Processing slice z= 24 25\n",
      "26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s].62it/s]\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slice z= "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing slice z= "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s]\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s]\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slice z="
     ]
    }
   ],
   "source": [
    "# Run the conversion in parallel. It's not a huge amount of processing but the more cores the better\n",
    "\n",
    "# First figure out if there are any planes that have already been converted \n",
    "# by checking the progress dir\n",
    "done_files = set([ int(z) for z in os.listdir(progress_dir) ])\n",
    "all_files = set(range(vol.bounds.minpt.z, vol.bounds.maxpt.z))\n",
    "# Figure out the ones we still need to convert \n",
    "to_upload = [ int(z) for z in list(all_files.difference(done_files)) ]\n",
    "to_upload.sort()\n",
    "print(f\"Have {len(to_upload)} planes to upload\")\n",
    "with ProcessPoolExecutor(max_workers=cpus_to_use) as executor:\n",
    "    for result in executor.map(process_slice,to_upload):\n",
    "        try:\n",
    "            print(result)\n",
    "        except Exception as exc:\n",
    "            print(f'generated an exception: {exc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Host the precomputed data on your machine so that Neuroglancer can see it\n",
    "This step is really easy! Note: Exectuing the code below will cause your jupyter notebook to hang, so it is better to run the following code in a new ipython terminal (make sure to have the ng_mriatlas conda environment activated in that python session) rather than the notebook. \n",
    "\n",
    "```python\n",
    "from cloudvolume import CloudVolume\n",
    "vol = CloudVolume(f'file://{\"/full/layer_dir/path\"}')\n",
    "vol.viewer(port=1338)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: View your custom volume and labels in Neuroglancer\n",
    "Step 4 hosts your data via http on port 1338 of your local machine. To actually view your data in Neuroglancer, there are two ways to do this. You can either load the data in manually in the browser or load it in with python. \n",
    "\n",
    "For the manual method, open up the Braincogs Neuroglancer client: [https://nglancer.pni.princeton.edu](https://nglancer.pni.princeton.edu) (you must be using a Princeton VPN) and then click the \"+\" in the upper left hand corner of the screen once the black screen loads. To load in your data, type the following into the source text box:<br>\n",
    "> precomputed://http://localhost:1338 <br>\n",
    "\n",
    "Then hit tab and name your layer if you'd like. Hit enter or the \"add layer\" button and your layer should load into Neuroglancer. Hopefully the labels you added should be showing up in the bottom left when you hover over a region. \n",
    "\n",
    "For the python method, you can do this by executing the following cells. Make sure you have hosted the data in another python instance somewhere on your local machine at port 1338."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ng_mriatlas",
   "language": "python",
   "name": "ng_mriatlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
